---
title: "00_summary"
author: "randy"
date: "2022-05-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# [Dynamic Predictions in Bayesian Functional Joint Models for Longitudinal and Time-to-Event Data: An Application to Alzheimer’s Disease](https://pubmed.ncbi.nlm.nih.gov/28750578/)


- a functional joint model to account for predictors in both longitudinal and survival submodels in the joint modeling framework.

- develop a Bayesian approach for parameter estimation and a dynamic prediction framework for predicting the subjects' future outcome trajectories and risk of dementia, based on their scalar and functional measurements. T


- Bayesian functional joint model provides a flexible framework to incorporate many features both in joint modeling of longitudinal and survival data and in functional data analysis. 



## Joint model 

- longitudinal

- survival (cox ph)

- link them using a common latent structure

## Dynamic prediction

dynamic personalized prediction of future; 
the dynamic prediction frameworks is that the predictive measures can be dynamically updated 
as additional longitudinal measurements become available for the target subjects

$$
y_i(t_{ij}) = m_i (t_{ij}) + \epsilon_{ij}\\
m_i(t_{ij}) = \beta_0 + x_{ij}^T \beta + \int g^{(x)}_i (s) B^{(x)}(s) ds + z^T u_i,
$$

$$
h_i(t) = h_0(t) \exp \{w^T_i \gamma + 
\int_{S} g^{(w)}_i(s) B^{(w)}(s) ds + \alpha m_i(t)\}
$$


use functional principal component scores
similar to Eigen-decomposition

Score, Eigen-value, and Eigen-vector


## Bayesian inference

The key step for prediction is to obtain samples for subject N’s 
random effect vector $u_N$ from its posterior distribution






## Jeremy paper 
Reviewer(s)' Comments to Author:

Reviewer: 1

Comments to the Author
Thank you for the opportunity to review this study. I found it well-written and clearly described. While I understand this is a comparative/validation portion of the PLM model development phase, I think the paper would be strengthened by discussion on PLM's translation to a healthcare setting:


1. The authors note they designed the study with clinical application in mind. I absolutely agree that clinically predictive methodologies should be developed with the end result - presumably clinical implementation  - in mind. Given that, I would have liked to have seen this addressed more. What are some future directions for the PLM model (eg integration into an EMR, decision alerts, etc.)? It's clear PLM method should be considered for use, but how exactly does one use it?

two perspectives: the statistical and clinical advantages of plm models.

- dynamic and predictive methods
- multiple time points propensity score
- assigned to a particular treatment given a set of observed covariates
- to reduce selection bias by equating groups based on these covariates.

which directly related to the question 3. 


2. Relatedly, the authors note they used limited parameters to keep it easy to use, but end the discussion with saying the PLM isn't easy to use (ie it is computationally intensive and may pose logistical challenges). What is a reader to think with these seemingly discordant messages? If the authors could add a paragraph that describes how they envision the PLM method being used in real world setting, that would significantly strengthen the message of the study.

those are two different directions,
plm conceptively and computationally challenging, but pratically easy to use.
like a smart phone, everybody can use it, but none of us understands it.

3. Do the authors have any commentary related to the differing geographic areas utilized? As I understood it, the training data come from Colorado, and testing from South Carolina. These states are on the extreme ends of the obesity (https://www.cdc.gov/obesity/data/prevalence-maps.html) and physical activity (https://www.cdc.gov/nchs/data/nhsr/nhsr112.pdf) continuums and table 2 shows some interesting differences in BMI and TUG for example. Perhaps beyond the scope of the study, but it might be an interesting addition if the authors could briefly address the implications of the geographic diversity of the datasets.

This is one of advantages for plm methods 
Glad the reviewer bring this up

because we do not need to consider the confounder or collider for the model 
plm is flexiable and accurate enough to capture the trend

Reviewer: 2

Comments to the Author

1. Please clarify what you mean by “without selection criteria.”  Was this a convenience sample?  How many total TKA patients were seen at each location and how many were included?

you know better than me


2. Although the two datasets differ significantly in several characteristics, The PLM model performed well in the testing dataset, compared to the LMM.  Does this suggest that the PLM model may be more generalizable?

yes, and could be addressed by quoting from the first reviewer comments on locations


3. For Figure 1, age and sex seem to be very basic demographic data, even for a physical therapy clinic – why would over a hundred be missing for each of these parameters?  In the end, only 30% of the patient records at the testing site were used.  This suggests that the data may be problematic – trustworthy? Was this the appropriate dataset to use for testing?  Another approach may have been to divide the training data set into a training and testing partition, and use the testing dataset for external validation.


4. Overall, the reviewer finds that the most interesting aspect of the manuscript is the quantification or visualization of uncertainty around a prediction.  The discussion in the manuscript is well done and I agree with the author’s approach using a confidence interval and visualization.  The possibility of seeing the observed recovery data for previous similar patients is also a very interesting proposition.

Thanks







